{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d46a19f8",
   "metadata": {},
   "source": [
    "# Week 11: Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb686bf",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called overfitting. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a test set X_test, y_test.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "### Underfitting and Overfitting\n",
    "\n",
    "In statistics, overfitting is \"the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably\". An overfitted model is a statistical model that contains more parameters than can be justified by the data.\n",
    "\n",
    "If you're overfitting, or you are getting great training scores and poor  test scores, try removing the lesser performing features. The model is just memorizing the training data.\n",
    "\n",
    "Underfitting occurs when a statistical model cannot adequately capture the underlying structure of the data. An under-fitted model is a model where some parameters or terms that would appear in a correctly specified model are missing.[2] Under-fitting would occur, for example, when fitting a linear model to non-linear data. Such a model will tend to have poor predictive performance.\n",
    "\n",
    "If you're underfitting, or you are getting poor training scores and test scores, try adding more data or more features.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Overfitting\n",
    "\n",
    "Please review the following regarding under-fitting and over-fitting:<br />\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html\n",
    "\n",
    "### Underfitting / Overfitting Fixes\n",
    "\n",
    "#### Underfitting\n",
    "* Get more data\n",
    "* Get more features\n",
    "\n",
    "#### Overfitting:\n",
    "* Cross Validation\n",
    "* Regularization\n",
    "* Remove weak features\n",
    "\n",
    "https://medium.com/ml-research-lab/under-fitting-over-fitting-and-its-solution-dc6191e34250\n",
    "\n",
    "### Supervised vs Unsupervised\n",
    "\n",
    "* Supervised: Uses target with model.fit\n",
    "* Unsupervised: Doesn't use target with model.fit\n",
    "\n",
    "## Out of Sample Testing (Cross Validation)\n",
    "\n",
    "Sometimes called rotation estimation or out-of-sample testing, is any of various similar model validation techniques for assessing how the results of a statistical analysis will generalize to an independent data set. It is mainly used in settings where the goal is prediction, and one wants to estimate how accurately a predictive model will perform in practice. In a prediction problem, a model is usually given a dataset of known data on which training is run (training dataset), and a dataset of unknown data (or first seen data) against which the model is tested (called the validation dataset or testing set). The goal of cross-validation, out of sample testing, is to test the model's ability to predict new data that was not used in estimating it, in order to flag problems like overfitting or selection bias and to give an insight on how the model will generalize to an independent dataset (i.e., an unknown dataset, for instance from a real problem).\n",
    "\n",
    "https://en.wikipedia.org/wiki/Cross-validation_(statistics)\n",
    "\n",
    "## K-fold Cross Validation \n",
    "\n",
    "In k-fold cross-validation, the original sample is randomly partitioned into k equal sized subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k âˆ’ 1 subsamples are used as training data. The cross-validation process is then repeated k times, with each of the k subsamples used exactly once as the validation data. The k results can then be averaged to produce a single estimation. The advantage of this method over repeated random sub-sampling is that all observations are used for both training and validation, and each observation is used for validation exactly once. 10-fold cross-validation is commonly used, but in general k remains an unfixed parameter.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc5726a",
   "metadata": {},
   "source": [
    "## Cross Validation Using a Decision Tree Classifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64bfb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91666667 1.         1.         1.         0.91666667 0.83333333\n",
      " 0.91666667 0.83333333 0.91666667 0.91666667]\n",
      "With Cross Validation: 0.9333333333333332\n",
      "Without Cross Validation: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "df = pd.DataFrame(data=X, columns=iris.feature_names)\n",
    "df['species'] = y\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('species', axis=1), df['species'], test_size=0.20)\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(cross_val_score(model, X_train, y_train, cv=10))\n",
    "print(f'With Cross Validation: {cross_val_score(model, X_train, y_train, cv=10).mean()}') \n",
    "print(f'Without Cross Validation: {accuracy_score(y_test, predictions)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
